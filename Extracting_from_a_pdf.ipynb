{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lZmB4d3uobSRjTc2FEkm4TzUv9uiL5Lq",
      "authorship_tag": "ABX9TyMMs54o6dX+caAPKgwD/bfe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukishore33/Extraction-of-text-from-pdf-to-excel/blob/main/Extracting_from_a_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HQQtV4J-WrR",
        "outputId": "ebd59a41-ae2d-4597-c0dc-aef5ae371cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.10.2-py3-none-any.whl (47 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20221105 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.20.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
            "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20221105 pdfplumber-0.10.2 pypdfium2-4.20.0\n"
          ]
        }
      ],
      "source": [
        "# Installing Libraries\n",
        "pip install pdfplumber"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "KiYzYeAlRaIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "L8ho9vNdCqk2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset"
      ],
      "metadata": {
        "id": "DsLtyKvoRi-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_files = [\"/content/drive/MyDrive/Data Science Projects/Marsh MCLenn/Assignment_sample_1.pdf\",\"/content/drive/MyDrive/Data Science Projects/Marsh MCLenn/Assignment_sample_2.pdf\"] #Importing Dataset"
      ],
      "metadata": {
        "id": "5qJ5teV8R3lS"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Empty DataFrame"
      ],
      "metadata": {
        "id": "07Iz40HTSOUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame(columns=[\"File Name\", \"Page Number\", \"Paragraph\", \"num_flag\", \"num_list\"]) #Creation of empty Dataframe"
      ],
      "metadata": {
        "id": "b8Dxua3QSNvN"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Functions to filter and extract the text in pdf.\n"
      ],
      "metadata": {
        "id": "R0Z7sT32TRcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function removes numbers and dates from a paragraph\n",
        "def clean_paragraph(paragraph):\n",
        "    pattern = r'\\b\\d+\\b|\\d{1,2}/\\d{1,2}/\\d{2,4}'  # Matches numbers and dates (e.g., 123, 12/31/2022)\n",
        "    return re.sub(pattern, '', paragraph) # returns cleaned paragraph\n",
        "\n",
        "# This function extracts and processes text from a file\n",
        "def process_pdf(pdf_file):\n",
        "    with pdfplumber.open(pdf_file) as pdf:\n",
        "        for page_number, page in enumerate(pdf.pages, start=1): # loops and gives specific number using enumerate function for every page\n",
        "            text_content = page.extract_text()  # Extracts Text from the Paragraph\n",
        "            paragraphs = text_content.rsplit('.\\n') # Splits paragraphs using delimiter . followed by a line(For paragraph separation)\n",
        "            for paragraph in paragraphs: # Loops every paragraph\n",
        "                cleaned_paragraph = clean_paragraph(paragraph) # Removes Numbers and Dates in paragraph\n",
        "                num_flag = 1 if re.search(r'\\b\\d+\\b', paragraph) else 0 # Creates a new column that checks whether number is present or absent in a paragraph\n",
        "                num_list = \",\".join(re.findall(r'\\b\\d+\\b', paragraph)) # creates a column number list and stores only the number related data in it\n",
        "                final_df.loc[len(final_df)] = [os.path.basename(pdf_file), page_number, cleaned_paragraph.strip(), num_flag, num_list] # Gets the specific data for each row\n"
      ],
      "metadata": {
        "id": "4Ib9aZUATRMQ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting each PDF's and generating text"
      ],
      "metadata": {
        "id": "oDG9RzlIUqm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting text from each pdfs\n",
        "for pdf_file in pdf_files:\n",
        "    process_pdf(pdf_file)"
      ],
      "metadata": {
        "id": "xXiANDHdTnm0"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking The Dataframe"
      ],
      "metadata": {
        "id": "RrPFA-i3WOTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether the data is read correctly or not\n",
        "print(final_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_rW7jGbTy5o",
        "outputId": "65eb670b-b6e6-4d32-9f80-7fa4bb9bead1"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  File Name  Page Number  \\\n",
            "0   Assignment_sample_1.pdf            1   \n",
            "1   Assignment_sample_1.pdf            1   \n",
            "2   Assignment_sample_1.pdf            1   \n",
            "3   Assignment_sample_1.pdf            1   \n",
            "4   Assignment_sample_1.pdf            1   \n",
            "..                      ...          ...   \n",
            "95  Assignment_sample_2.pdf            8   \n",
            "96  Assignment_sample_2.pdf            8   \n",
            "97  Assignment_sample_2.pdf            8   \n",
            "98  Assignment_sample_2.pdf            8   \n",
            "99  Assignment_sample_2.pdf            9   \n",
            "\n",
            "                                            Paragraph  num_flag  \\\n",
            "0   ANNUAL REPORT \\nDear Valued Shareholders,\\nOn ...         1   \n",
            "1   ae\\n(Ew\\nKeeping Agile To Seize Opportunities ...         1   \n",
            "2   Our diversified business model, both in terms ...         1   \n",
            "3   Back On Growth Track\\nFor FY , AKI recorded a ...         1   \n",
            "4   Total operating expenses (excluding finance co...         0   \n",
            "..                                                ...       ...   \n",
            "95                   KALPATARU POWER TRANSMISSION LTD         0   \n",
            "96  REGISTERED OFFICE : Plot No. , Part III, G.I.D...         1   \n",
            "97                     Particulars ,  ,  ,  ,  , \\nNo         1   \n",
            "98  (Audited) (Unaudited) (Audited) (Audited) (Aud...         1   \n",
            "99  Statement of Assets & Liabilities (Rs. in Cror...         1   \n",
            "\n",
            "                                             num_list  \n",
            "0                                2022,31,2022,2021,22  \n",
            "1                                          19,2020,19  \n",
            "2                                  84,59,1,64,2022,19  \n",
            "3                 2022,63,61,32,98,47,83,31,2021,2021  \n",
            "4                                                      \n",
            "..                                                ...  \n",
            "95                                                     \n",
            "96  101,28,382,028,91,79,232,14000,91,79,232,11966...  \n",
            "97            31,2023,31,2022,31,2022,31,2023,31,2022  \n",
            "98  4,4,1,4,882,4,004,4,135,16,361,14,777,2,14,2,3...  \n",
            "99  1,31,2023,31,2022,1,981,1,627,52,20,106,134,1,...  \n",
            "\n",
            "[100 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking top 50 paragraphs whether the data is extracted as we needed or not."
      ],
      "metadata": {
        "id": "-sQzDlmGVMmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['Page Number'].value_counts() # checking counts of paragraphs that is rows for every page."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJxp0dOlcfaM",
        "outputId": "7a95ddcc-2fa1-4f69-f93d-ea05c46f6f17"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    18\n",
              "2    15\n",
              "4    15\n",
              "1    13\n",
              "6    11\n",
              "8     9\n",
              "9     9\n",
              "3     5\n",
              "7     5\n",
              "Name: Page Number, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df['Paragraph'].head(50) # checking top 50 paragraphs."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdsCeoAqQxuk",
        "outputId": "d2d376e0-2c76-4edc-ca6f-f64ef8afba80"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     ANNUAL REPORT \\nDear Valued Shareholders,\\nOn ...\n",
              "1     ae\\n(Ew\\nKeeping Agile To Seize Opportunities ...\n",
              "2     Our diversified business model, both in terms ...\n",
              "3     Back On Growth Track\\nFor FY , AKI recorded a ...\n",
              "4     Total operating expenses (excluding finance co...\n",
              "5     The balance sheet remained sound, with cash an...\n",
              "6     Dawn Of A New Growth Cycle\\nAs the global econ...\n",
              "7     However, we are mindful of the ongoing macro v...\n",
              "8     ANNUAL REPORT \\nWe will strive to enhance our ...\n",
              "9     Besides our strong customer centricity, we wil...\n",
              "10    Sustainability\\nAKI has always regarded sustai...\n",
              "11    Words of appreciation\\n| would like to thank t...\n",
              "12    Last but not least, | would like to show appre...\n",
              "13    In this dawn of a new growth cycle, | believe ...\n",
              "14    ANNUAL REPORT \\nNOTICE\\nNOTICE is hereby given...\n",
              "15    ANNUAL REPORT \\nNOTES:\\n. A MEMBER ENTITLED TO...\n",
              "16    A person can act as a proxy on behalf of membe...\n",
              "17    The holder of proxy shall prove his identity a...\n",
              "18    . In terms of the provisions of Section  of th...\n",
              "19    None of the directors were interested in the s...\n",
              "20    ANNUAL REPORT \\nFor receiving all communicatio...\n",
              "21    (b) Members holding shares in dematerialized m...\n",
              "22    Attendance slip, proxy form and the route map ...\n",
              "23    Members holding shares in Physical form can su...\n",
              "24    . Breif resume of Directors/persons proposed t...\n",
              "25    . All documents referred to in accompanying No...\n",
              "26    DATE : -- By Order of the Board\\nPLACE: KANPUR...\n",
              "27    ANNUAL REPORT \\nAdditional Infromation of Dire...\n",
              "28    Chairmanship/ Membership of Committees in Non ...\n",
              "29    ANNUAL REPORT \\nStatement Containing Informati...\n",
              "30    . Nature of Industry:\\nMANUFACTURING, TRADE AN...\n",
              "31    . Date or expected date of Commencement of Com...\n",
              "32    ANNUAL REPORT \\nDear Shareholders,\\nThe Direct...\n",
              "33    The management continues to pursue its efforts...\n",
              "34    There is no change in nature of business of th...\n",
              "35    DIVIDEND\\nYour Directors regret their inabilit...\n",
              "36    BONUS\\nYour company has issued Bonus Shares in...\n",
              "37    ANNUAL REPORT \\nTRANSFER TO RESERVES\\nDuring t...\n",
              "38    COMPANIES POLICY ON DIRECTORS APPOINTMENT AND ...\n",
              "39    Nomination and Remuneration Committee has chec...\n",
              "40    MATERIAL CHANGES AND COMMITMENTS, IF ANY, AFFE...\n",
              "41    PARTICULARS OF LOANS, GUARANTEES & INVESTMENTS...\n",
              "42    LEGAL FRAMEWORK AND REPORTING STRUCTURE:\\nThe ...\n",
              "43    CSR ACTIVITIES:\\nCSR Activities are not applic...\n",
              "44    The Company has following Committees of the Bo...\n",
              "45    KPTL/-\\n8th May, \\nBSE Limited National Stock ...\n",
              "46    Corporate Relationship Department ‘Exchange Pl...\n",
              "47    b) recommended final Dividend of Rs. /- per Eq...\n",
              "48    c) approved the proposal for issuance of secur...\n",
              "49    d) approved the re-appointment of M/s. B S R &...\n",
              "Name: Paragraph, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Data Types of Columns"
      ],
      "metadata": {
        "id": "TtQXBEaXWkSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.dtypes # checking data types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOyejYOMWuo2",
        "outputId": "8db90302-5b39-44dc-9d3b-2571d6b02175"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "File Name      object\n",
              "Page Number     int64\n",
              "Paragraph      object\n",
              "num_flag        int64\n",
              "num_list       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Dataframe into Excel sheet."
      ],
      "metadata": {
        "id": "8NDUCQhcVd4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('Extracted_file.csv') # saving the extracted file"
      ],
      "metadata": {
        "id": "ovxGPGfcVlrx"
      },
      "execution_count": 103,
      "outputs": []
    }
  ]
}